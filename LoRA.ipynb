{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVAeUJ9THNqPiffgJXqlLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guanyaohan/HW1/blob/master/LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbwyBmJZmxW3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, Dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "print(\"Loading SST2 dataset...\")\n",
        "dataset = load_dataset(\"sst2\")\n",
        "\n",
        "# Prepare datasets\n",
        "print(\"Preparing datasets...\")\n",
        "train_dataset = dataset[\"train\"]\n",
        "original_val_dataset = dataset[\"validation\"]\n",
        "\n",
        "val_size = len(original_val_dataset) // 2\n",
        "val_dataset = Dataset.from_dict(original_val_dataset[:val_size])\n",
        "test_dataset = Dataset.from_dict(original_val_dataset[val_size:])\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"New validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"New test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# Load RoBERTa tokenizer and model\n",
        "print(\"Loading RoBERTa tokenizer and model...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Configure LoRA\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"query\", \"key\", \"value\"]\n",
        ")\n",
        "\n",
        "# Wrap the model with LoRA\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "# Process dataset function\n",
        "def process_dataset(dataset, split_name):\n",
        "    print(f\"Processing {split_name} dataset...\")\n",
        "    tokenized = dataset.map(tokenize_function, batched=True, remove_columns=['sentence', 'idx'])\n",
        "    tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    labels = tokenized['labels']\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    print(f\"{split_name} dataset label distribution: {dict(zip(unique_labels, counts))}\")\n",
        "    print(f\"{split_name} dataset - Processed size: {len(tokenized)}\")\n",
        "    return tokenized\n",
        "\n",
        "tokenized_datasets = {\n",
        "    \"train\": process_dataset(train_dataset, \"train\"),\n",
        "    \"validation\": process_dataset(val_dataset, \"validation\"),\n",
        "    \"test\": process_dataset(test_dataset, \"test\")\n",
        "}\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        if self.args.logging_steps > 0 and self.state.global_step % self.args.logging_steps == 0:\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            accuracy = torch.sum(predictions == labels).item() / len(labels)\n",
        "            self.log({\"train_accuracy\": accuracy})\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, predictions)\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_lora\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs_lora\",\n",
        "    logging_steps=5,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=25,\n",
        "    save_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "steps = []\n",
        "val_steps = []\n",
        "\n",
        "last_step = 0\n",
        "for log in trainer.state.log_history:\n",
        "    if 'step' in log:\n",
        "        last_step = log['step']\n",
        "\n",
        "    if 'loss' in log and 'step' in log:\n",
        "        steps.append(log['step'])\n",
        "        train_loss.append(log['loss'])\n",
        "        if len(train_acc) < len(steps):\n",
        "            train_acc.append(None)\n",
        "\n",
        "    if 'train_accuracy' in log:\n",
        "        if len(steps) > 0 and steps[-1] == last_step:\n",
        "            train_acc[-1] = log['train_accuracy']\n",
        "        else:\n",
        "            steps.append(last_step)\n",
        "            train_acc.append(log['train_accuracy'])\n",
        "            train_loss.append(None)\n",
        "\n",
        "    if 'eval_accuracy' in log and 'step' in log:\n",
        "        val_steps.append(log['step'])\n",
        "        val_acc.append(log['eval_accuracy'])\n",
        "\n",
        "max_length = max(len(steps), len(train_loss), len(train_acc))\n",
        "steps = steps + [steps[-1]] * (max_length - len(steps))\n",
        "train_loss = train_loss + [None] * (max_length - len(train_loss))\n",
        "train_acc = train_acc + [None] * (max_length - len(train_acc))\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n",
        "\n",
        "ax1.plot([step for step, loss in zip(steps, train_loss) if loss is not None],\n",
        "         [loss for loss in train_loss if loss is not None],\n",
        "         label='Train Loss', color='blue')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training Loss')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot([step for step, acc in zip(steps, train_acc) if acc is not None],\n",
        "         [acc for acc in train_acc if acc is not None],\n",
        "         label='Train Accuracy', color='green')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "ax3.plot(val_steps, val_acc, label='Validation Accuracy', color='red')\n",
        "ax3.set_ylabel('Accuracy')\n",
        "ax3.set_title('Validation Accuracy')\n",
        "ax3.legend()\n",
        "\n",
        "ax3.set_xlabel('Steps')\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_metrics_lora.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Training completed. LoRA metrics plot saved as 'training_metrics_lora.png'.\")\n",
        "\n",
        "# Print final metrics\n",
        "print(f\"Final training loss: {next((loss for loss in reversed(train_loss) if loss is not None), 'N/A')}\")\n",
        "print(f\"Final training accuracy: {next((acc for acc in reversed(train_acc) if acc is not None), 'N/A')}\")\n",
        "print(f\"Final validation accuracy: {val_acc[-1] if val_acc else 'N/A'}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "print(f\"Test set results: {test_results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b3ec70960a0543689f83f9b77fc0578a",
            "64a66ce493f348b59c4f746a35a1269c",
            "941ada27923444c795094dcd5fa91a12",
            "9c7b09a42fcf4736b58e84cf7dbebd23",
            "71aefe7b01354d4f9d97f2aecff0353a",
            "420a400749c74e7fb8458009eab0ecbf",
            "2893e5c0bb314287a65dc8689d4d0a53",
            "67f791d9933b41ef9c3a7b063a18ebe0",
            "d95650fe0bbe46dd9e7a49f2cb92ca24",
            "f5208f6240974fdead6418f08df07460",
            "de41a437740b45649cf86bbc76b93563",
            "fb71271edb4543babee4dd004095cc05",
            "89ab3303f7364b0b93394f4f07679a7e",
            "664f5516298340cab6881188df6909d2",
            "0cef4aa3efed426982d8916ee74fdda1",
            "ec53a35f61b24fd888edebd774f55ace",
            "44794bced7934fe2bbf51fc1c81381c2",
            "f2151a1e6d234439be53967e8a0b85f4",
            "96356b0b06d3447490f2c41f1920ee26",
            "99df056d2b744536ad163c27ea2ce4ce",
            "1458b9a8c6fc4df5b73476e512cb424c",
            "37190e1bba3f42e4b01eca5649fed23b"
          ]
        },
        "id": "vGCiNeaUADfW",
        "outputId": "cefe87d5-0709-47d3-a65d-0fa881a1789c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SST2 dataset...\n",
            "Preparing datasets...\n",
            "Train dataset size: 67349\n",
            "New validation dataset size: 436\n",
            "New test dataset size: 436\n",
            "Loading RoBERTa tokenizer and model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,034,498 || all params: 125,681,668 || trainable%: 0.8231\n",
            "Processing train dataset...\n",
            "train dataset label distribution: {0: 29780, 1: 37569}\n",
            "train dataset - Processed size: 67349\n",
            "Processing validation dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/436 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3ec70960a0543689f83f9b77fc0578a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation dataset label distribution: {0: 208, 1: 228}\n",
            "validation dataset - Processed size: 436\n",
            "Processing test dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/436 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb71271edb4543babee4dd004095cc05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test dataset label distribution: {0: 220, 1: 216}\n",
            "test dataset - Processed size: 436\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4210/4210 07:55, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.675500</td>\n",
              "      <td>0.692064</td>\n",
              "      <td>0.522936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.684600</td>\n",
              "      <td>0.692320</td>\n",
              "      <td>0.522936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.688100</td>\n",
              "      <td>0.691130</td>\n",
              "      <td>0.522936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.686200</td>\n",
              "      <td>0.691447</td>\n",
              "      <td>0.522936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.708200</td>\n",
              "      <td>0.699434</td>\n",
              "      <td>0.522936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.689900</td>\n",
              "      <td>0.683067</td>\n",
              "      <td>0.522936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.673100</td>\n",
              "      <td>0.660867</td>\n",
              "      <td>0.527523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.531700</td>\n",
              "      <td>0.472787</td>\n",
              "      <td>0.880734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.297000</td>\n",
              "      <td>0.331118</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.335949</td>\n",
              "      <td>0.887615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.355800</td>\n",
              "      <td>0.277773</td>\n",
              "      <td>0.896789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.223100</td>\n",
              "      <td>0.322180</td>\n",
              "      <td>0.892202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.455900</td>\n",
              "      <td>0.260589</td>\n",
              "      <td>0.901376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.271346</td>\n",
              "      <td>0.905963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.372900</td>\n",
              "      <td>0.245867</td>\n",
              "      <td>0.905963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.265800</td>\n",
              "      <td>0.236208</td>\n",
              "      <td>0.905963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.409000</td>\n",
              "      <td>0.288657</td>\n",
              "      <td>0.896789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.289900</td>\n",
              "      <td>0.252207</td>\n",
              "      <td>0.901376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.336000</td>\n",
              "      <td>0.222403</td>\n",
              "      <td>0.912844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.271100</td>\n",
              "      <td>0.248537</td>\n",
              "      <td>0.899083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.403300</td>\n",
              "      <td>0.234199</td>\n",
              "      <td>0.908257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.284300</td>\n",
              "      <td>0.222838</td>\n",
              "      <td>0.919725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.293200</td>\n",
              "      <td>0.218531</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.299900</td>\n",
              "      <td>0.222307</td>\n",
              "      <td>0.915138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.220700</td>\n",
              "      <td>0.217808</td>\n",
              "      <td>0.915138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.315100</td>\n",
              "      <td>0.243498</td>\n",
              "      <td>0.912844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.236600</td>\n",
              "      <td>0.210543</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.292500</td>\n",
              "      <td>0.231579</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.311600</td>\n",
              "      <td>0.206724</td>\n",
              "      <td>0.915138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.193600</td>\n",
              "      <td>0.205409</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>0.335600</td>\n",
              "      <td>0.217118</td>\n",
              "      <td>0.919725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.282900</td>\n",
              "      <td>0.213298</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>0.208618</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.273200</td>\n",
              "      <td>0.197965</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.333400</td>\n",
              "      <td>0.196348</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.303900</td>\n",
              "      <td>0.193467</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>0.327600</td>\n",
              "      <td>0.218195</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.405300</td>\n",
              "      <td>0.199361</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.286800</td>\n",
              "      <td>0.193165</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.240900</td>\n",
              "      <td>0.202323</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>0.288000</td>\n",
              "      <td>0.200082</td>\n",
              "      <td>0.919725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.498800</td>\n",
              "      <td>0.204863</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>0.289100</td>\n",
              "      <td>0.217774</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.303300</td>\n",
              "      <td>0.198860</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>0.217851</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.191900</td>\n",
              "      <td>0.198482</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>0.289700</td>\n",
              "      <td>0.222667</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.304900</td>\n",
              "      <td>0.210454</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.243100</td>\n",
              "      <td>0.197994</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.284500</td>\n",
              "      <td>0.196268</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.315700</td>\n",
              "      <td>0.225348</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.330300</td>\n",
              "      <td>0.196985</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.238800</td>\n",
              "      <td>0.200247</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.274000</td>\n",
              "      <td>0.192726</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>0.159800</td>\n",
              "      <td>0.218805</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.280800</td>\n",
              "      <td>0.198018</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>0.365400</td>\n",
              "      <td>0.190071</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>0.191412</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>0.370300</td>\n",
              "      <td>0.189140</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.246100</td>\n",
              "      <td>0.198334</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>0.262700</td>\n",
              "      <td>0.194620</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.290700</td>\n",
              "      <td>0.194286</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>0.384000</td>\n",
              "      <td>0.194201</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.223200</td>\n",
              "      <td>0.194332</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>0.397900</td>\n",
              "      <td>0.242060</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.317600</td>\n",
              "      <td>0.191272</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>0.217100</td>\n",
              "      <td>0.198794</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.150500</td>\n",
              "      <td>0.200576</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>0.337200</td>\n",
              "      <td>0.204068</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.165500</td>\n",
              "      <td>0.199978</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>0.409900</td>\n",
              "      <td>0.197278</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.285000</td>\n",
              "      <td>0.186760</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>0.279500</td>\n",
              "      <td>0.189546</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.240800</td>\n",
              "      <td>0.190880</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>0.279500</td>\n",
              "      <td>0.196068</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.230100</td>\n",
              "      <td>0.188829</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>0.390600</td>\n",
              "      <td>0.191942</td>\n",
              "      <td>0.935780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.396800</td>\n",
              "      <td>0.201148</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>0.221500</td>\n",
              "      <td>0.203065</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.271200</td>\n",
              "      <td>0.199167</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>0.315100</td>\n",
              "      <td>0.190310</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.283100</td>\n",
              "      <td>0.186463</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>0.201900</td>\n",
              "      <td>0.195758</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.359900</td>\n",
              "      <td>0.189252</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.322300</td>\n",
              "      <td>0.197703</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.196932</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>0.360500</td>\n",
              "      <td>0.195995</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.259600</td>\n",
              "      <td>0.186593</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.357800</td>\n",
              "      <td>0.199436</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.155800</td>\n",
              "      <td>0.215952</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>0.239800</td>\n",
              "      <td>0.205129</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.097900</td>\n",
              "      <td>0.197225</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>0.228600</td>\n",
              "      <td>0.210601</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>0.204392</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.346300</td>\n",
              "      <td>0.200050</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.244500</td>\n",
              "      <td>0.205626</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.307100</td>\n",
              "      <td>0.193713</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.373800</td>\n",
              "      <td>0.202841</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.253100</td>\n",
              "      <td>0.208567</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.090500</td>\n",
              "      <td>0.193571</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>0.198600</td>\n",
              "      <td>0.204817</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.208200</td>\n",
              "      <td>0.205750</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>0.313400</td>\n",
              "      <td>0.202778</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.200285</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.197793</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.265200</td>\n",
              "      <td>0.194109</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>0.218000</td>\n",
              "      <td>0.192142</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.250200</td>\n",
              "      <td>0.207835</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>0.290500</td>\n",
              "      <td>0.211980</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.217900</td>\n",
              "      <td>0.209021</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>0.248600</td>\n",
              "      <td>0.208712</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.229100</td>\n",
              "      <td>0.200114</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2825</td>\n",
              "      <td>0.233400</td>\n",
              "      <td>0.201637</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.258400</td>\n",
              "      <td>0.198781</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2875</td>\n",
              "      <td>0.257700</td>\n",
              "      <td>0.198316</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.181000</td>\n",
              "      <td>0.193259</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2925</td>\n",
              "      <td>0.275600</td>\n",
              "      <td>0.196577</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.241300</td>\n",
              "      <td>0.194620</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>0.243100</td>\n",
              "      <td>0.206258</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.295100</td>\n",
              "      <td>0.198927</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3025</td>\n",
              "      <td>0.248700</td>\n",
              "      <td>0.202073</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.201900</td>\n",
              "      <td>0.216976</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3075</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.203401</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.191300</td>\n",
              "      <td>0.204599</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3125</td>\n",
              "      <td>0.225200</td>\n",
              "      <td>0.215399</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.293100</td>\n",
              "      <td>0.213466</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3175</td>\n",
              "      <td>0.232700</td>\n",
              "      <td>0.203755</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.203119</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3225</td>\n",
              "      <td>0.348600</td>\n",
              "      <td>0.204024</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.255100</td>\n",
              "      <td>0.199625</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3275</td>\n",
              "      <td>0.363800</td>\n",
              "      <td>0.198624</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.209000</td>\n",
              "      <td>0.196299</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3325</td>\n",
              "      <td>0.212400</td>\n",
              "      <td>0.206138</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.284800</td>\n",
              "      <td>0.196739</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3375</td>\n",
              "      <td>0.294400</td>\n",
              "      <td>0.196126</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.150300</td>\n",
              "      <td>0.199650</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3425</td>\n",
              "      <td>0.248400</td>\n",
              "      <td>0.198235</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.221500</td>\n",
              "      <td>0.193624</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3475</td>\n",
              "      <td>0.255000</td>\n",
              "      <td>0.198871</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.169600</td>\n",
              "      <td>0.201203</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3525</td>\n",
              "      <td>0.315400</td>\n",
              "      <td>0.197704</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.184400</td>\n",
              "      <td>0.196749</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3575</td>\n",
              "      <td>0.188700</td>\n",
              "      <td>0.196210</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.242500</td>\n",
              "      <td>0.196816</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3625</td>\n",
              "      <td>0.336800</td>\n",
              "      <td>0.188663</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.206400</td>\n",
              "      <td>0.187601</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3675</td>\n",
              "      <td>0.319400</td>\n",
              "      <td>0.192144</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.294300</td>\n",
              "      <td>0.189164</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3725</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.189287</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.316700</td>\n",
              "      <td>0.190048</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3775</td>\n",
              "      <td>0.313200</td>\n",
              "      <td>0.192263</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.211400</td>\n",
              "      <td>0.190169</td>\n",
              "      <td>0.933486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3825</td>\n",
              "      <td>0.257600</td>\n",
              "      <td>0.192005</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.320900</td>\n",
              "      <td>0.195367</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3875</td>\n",
              "      <td>0.258000</td>\n",
              "      <td>0.192269</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.126900</td>\n",
              "      <td>0.192902</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3925</td>\n",
              "      <td>0.314400</td>\n",
              "      <td>0.193815</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.293500</td>\n",
              "      <td>0.195921</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3975</td>\n",
              "      <td>0.165500</td>\n",
              "      <td>0.194876</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.308000</td>\n",
              "      <td>0.196253</td>\n",
              "      <td>0.928899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4025</td>\n",
              "      <td>0.205200</td>\n",
              "      <td>0.193830</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.261500</td>\n",
              "      <td>0.193830</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4075</td>\n",
              "      <td>0.196400</td>\n",
              "      <td>0.193057</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.225900</td>\n",
              "      <td>0.193524</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4125</td>\n",
              "      <td>0.127700</td>\n",
              "      <td>0.193231</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.193731</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4175</td>\n",
              "      <td>0.175600</td>\n",
              "      <td>0.193521</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.244600</td>\n",
              "      <td>0.193560</td>\n",
              "      <td>0.931193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed. LoRA metrics plot saved as 'training_metrics_lora.png'.\n",
            "Final training loss: 0.2315\n",
            "Final training accuracy: 0.875\n",
            "Final validation accuracy: 0.9311926605504587\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set results: {'eval_loss': 0.21537663042545319, 'eval_accuracy': 0.9220183486238532, 'eval_runtime': 0.7884, 'eval_samples_per_second': 553.021, 'eval_steps_per_second': 8.879, 'epoch': 1.0}\n"
          ]
        }
      ]
    }
  ]
}